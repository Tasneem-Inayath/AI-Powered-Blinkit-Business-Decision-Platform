{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dddbf59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: blinkit_customers.csv\n",
      "Columns: ['customer_id', 'customer_name', 'email', 'phone', 'address', 'area', 'pincode', 'registration_date', 'customer_segment', 'total_orders', 'avg_order_value']\n",
      "--------------------------------------------------\n",
      "File: blinkit_customer_feedback.csv\n",
      "Columns: ['feedback_id', 'order_id', 'customer_id', 'rating', 'feedback_text', 'feedback_category', 'sentiment', 'feedback_date']\n",
      "--------------------------------------------------\n",
      "File: blinkit_marketing_performance.csv\n",
      "Columns: ['campaign_id', 'campaign_name', 'date', 'target_audience', 'channel', 'impressions', 'clicks', 'conversions', 'spend', 'revenue_generated', 'roas']\n",
      "--------------------------------------------------\n",
      "File: blinkit_orders.csv\n",
      "Columns: ['order_id', 'customer_id', 'order_date', 'promised_delivery_time', 'actual_delivery_time', 'delivery_status', 'order_total', 'payment_method', 'delivery_partner_id', 'store_id']\n",
      "--------------------------------------------------\n",
      "File: blinkit_order_items.csv\n",
      "Columns: ['order_id', 'product_id', 'quantity', 'unit_price']\n",
      "--------------------------------------------------\n",
      "File: blinkit_products.csv\n",
      "Columns: ['product_id', 'product_name', 'category', 'brand', 'price', 'mrp', 'margin_percentage', 'shelf_life_days', 'min_stock_level', 'max_stock_level']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your folder containing CSV files\n",
    "folder_path = \"C:/Projects/final project/data\"\n",
    "\n",
    "# List to store column names from all CSVs\n",
    "all_columns = set()\n",
    "\n",
    "# Loop through all CSV files in the folder\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            print(f\"File: {file}\")\n",
    "            print(\"Columns:\", list(df.columns))\n",
    "            print(\"-\" * 50)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not read {file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a9a5ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tasneem Inayath\\AppData\\Local\\Temp\\ipykernel_10868\\3674095147.py:36: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGradientBoosting AUC: 0.4961950169437368\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# -------------------------\n",
    "# LOAD DATA\n",
    "# -------------------------\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    database=\"blinkit_db\",\n",
    "    user=\"postgres\",\n",
    "    password=\"2741\"\n",
    ")\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    order_id,\n",
    "    order_date,\n",
    "    hour_of_day,\n",
    "    day_of_week,\n",
    "    is_weekend,\n",
    "    area,\n",
    "    order_total,\n",
    "    total_items,\n",
    "    promised_duration_minutes,\n",
    "    is_late\n",
    "FROM ml_delivery_features\n",
    "ORDER BY order_date;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, conn)\n",
    "conn.close()\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "X = df.drop(columns=[\"order_id\", \"order_date\", \"is_late\"])\n",
    "y = df[\"is_late\"]\n",
    "\n",
    "# -------------------------\n",
    "# TIME-AWARE SPLIT\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, shuffle=False\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# PREPROCESSING\n",
    "# -------------------------\n",
    "categorical_cols = [\"area\"]\n",
    "numerical_cols = [\n",
    "    \"hour_of_day\",\n",
    "    \"day_of_week\",\n",
    "    \"is_weekend\",\n",
    "    \"order_total\",\n",
    "    \"total_items\",\n",
    "    \"promised_duration_minutes\"\n",
    "]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical_cols),\n",
    "        (\"num\", \"passthrough\", numerical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# MODEL\n",
    "# -------------------------\n",
    "model = HistGradientBoostingClassifier(\n",
    "    max_depth=6,\n",
    "    learning_rate=0.08,\n",
    "    max_iter=250,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"model\", model)\n",
    "])\n",
    "\n",
    "# -------------------------\n",
    "# TRAIN\n",
    "# -------------------------\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------\n",
    "# EVALUATE\n",
    "# -------------------------\n",
    "y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(\"HistGradientBoosting AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa98651b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tasneem Inayath\\AppData\\Local\\Temp\\ipykernel_10868\\95758556.py:37: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Delay Risk Model trained\n",
      "Model: RandomForestClassifier\n",
      "Features: area, hour_of_day, day_of_week, promised_duration_minutes\n",
      "\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.384     0.522     0.442       418\n",
      "           1      0.624     0.487     0.547       682\n",
      "\n",
      "    accuracy                          0.500      1100\n",
      "   macro avg      0.504     0.504     0.495      1100\n",
      "weighted avg      0.533     0.500     0.507      1100\n",
      "\n",
      "ROC-AUC: 0.4928\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# -----------------------------\n",
    "# LOAD DATA FROM POSTGRES\n",
    "# -----------------------------\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    database=\"blinkit_db\",\n",
    "    user=\"postgres\",\n",
    "    password=\"2741\"\n",
    ")\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    order_id,\n",
    "    order_date,\n",
    "    hour_of_day,\n",
    "    day_of_week,\n",
    "    is_weekend,\n",
    "    area,\n",
    "    order_total,\n",
    "    total_items,\n",
    "    promised_duration_minutes,\n",
    "    is_late\n",
    "FROM ml_delivery_features\n",
    "ORDER BY order_date;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, conn)\n",
    "conn.close()\n",
    "\n",
    "# -----------------------------\n",
    "# BASIC CLEANING\n",
    "# -----------------------------\n",
    "df = df.dropna(\n",
    "    subset=[\n",
    "        \"area\",\n",
    "        \"hour_of_day\",\n",
    "        \"day_of_week\",\n",
    "        \"promised_duration_minutes\",\n",
    "        \"is_late\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# FEATURES & TARGET\n",
    "# -----------------------------\n",
    "X = df[\n",
    "    [\"area\", \"hour_of_day\", \"day_of_week\", \"promised_duration_minutes\"]\n",
    "].copy()\n",
    "\n",
    "y = df[\"is_late\"].astype(int)\n",
    "\n",
    "# -----------------------------\n",
    "# TRAIN / TEST SPLIT\n",
    "# -----------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.22,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# PREPROCESSING\n",
    "# -----------------------------\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), [\"area\"]),\n",
    "        (\"num\", \"passthrough\",\n",
    "         [\"hour_of_day\", \"day_of_week\", \"promised_duration_minutes\"])\n",
    "    ]\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# RANDOM FOREST MODEL\n",
    "# -----------------------------\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=20,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# PIPELINE\n",
    "# -----------------------------\n",
    "pipe = Pipeline([\n",
    "    (\"pre\", pre),\n",
    "    (\"model\", model)\n",
    "])\n",
    "\n",
    "# -----------------------------\n",
    "# TRAIN\n",
    "# -----------------------------\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# -----------------------------\n",
    "# EVALUATION\n",
    "# -----------------------------\n",
    "proba = pipe.predict_proba(X_test)[:, 1]\n",
    "pred = (proba >= 0.5).astype(int)\n",
    "\n",
    "print(\"✅ Delay Risk Model trained\")\n",
    "print(\"Model: RandomForestClassifier\")\n",
    "print(\"Features: area, hour_of_day, day_of_week, promised_duration_minutes\")\n",
    "\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "print(classification_report(y_test, pred, digits=3))\n",
    "\n",
    "print(\"ROC-AUC:\", round(roc_auc_score(y_test, proba), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "355004a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['delivery_delay_model.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(pipe, \"delivery_delay_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f243bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total feedback rows: 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tasneem Inayath\\AppData\\Local\\Temp\\ipykernel_10868\\3234839245.py:30: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>feedback_text</th>\n",
       "      <th>feedback_category</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>feedback_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2234710</td>\n",
       "      <td>1961864118</td>\n",
       "      <td>It was okay, nothing special.</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2024-07-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5450964</td>\n",
       "      <td>1549769649</td>\n",
       "      <td>The order was incorrect.</td>\n",
       "      <td>App Experience</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2024-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>482108</td>\n",
       "      <td>9185164487</td>\n",
       "      <td>It was okay, nothing special.</td>\n",
       "      <td>App Experience</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2024-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4823104</td>\n",
       "      <td>9644738826</td>\n",
       "      <td>The product met my expectations.</td>\n",
       "      <td>App Experience</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2023-11-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3537464</td>\n",
       "      <td>5427684290</td>\n",
       "      <td>Product was damaged during delivery.</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2023-11-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feedback_id    order_id                         feedback_text  \\\n",
       "0      2234710  1961864118         It was okay, nothing special.   \n",
       "1      5450964  1549769649              The order was incorrect.   \n",
       "2       482108  9185164487         It was okay, nothing special.   \n",
       "3      4823104  9644738826      The product met my expectations.   \n",
       "4      3537464  5427684290  Product was damaged during delivery.   \n",
       "\n",
       "  feedback_category sentiment feedback_date  \n",
       "0          Delivery   Neutral    2024-07-17  \n",
       "1    App Experience  Negative    2024-05-28  \n",
       "2    App Experience   Neutral    2024-09-23  \n",
       "3    App Experience   Neutral    2023-11-24  \n",
       "4          Delivery  Negative    2023-11-20  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "# ---------------------------\n",
    "# DB CONNECTION\n",
    "# ---------------------------\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    database=\"blinkit_db\",\n",
    "    user=\"postgres\",\n",
    "    password=\"2741\"\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# LOAD FEEDBACK DATA\n",
    "# ---------------------------\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    feedback_id,\n",
    "    order_id,\n",
    "    feedback_text,\n",
    "    feedback_category,\n",
    "    sentiment,\n",
    "    feedback_date\n",
    "FROM blinkit_customer_feedback\n",
    "WHERE feedback_text IS NOT NULL\n",
    "  AND feedback_text <> '';\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, conn)\n",
    "conn.close()\n",
    "\n",
    "print(\"Total feedback rows:\", len(df))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb6967fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean feedback rows: 5000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback_text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It was okay, nothing special.</td>\n",
       "      <td>it was okay, nothing special.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The order was incorrect.</td>\n",
       "      <td>the order was incorrect.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It was okay, nothing special.</td>\n",
       "      <td>it was okay, nothing special.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The product met my expectations.</td>\n",
       "      <td>the product met my expectations.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Product was damaged during delivery.</td>\n",
       "      <td>product was damaged during delivery.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          feedback_text                            clean_text\n",
       "0         It was okay, nothing special.         it was okay, nothing special.\n",
       "1              The order was incorrect.              the order was incorrect.\n",
       "2         It was okay, nothing special.         it was okay, nothing special.\n",
       "3      The product met my expectations.      the product met my expectations.\n",
       "4  Product was damaged during delivery.  product was damaged during delivery."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# BASIC TEXT CLEANING\n",
    "# ---------------------------\n",
    "df[\"clean_text\"] = (\n",
    "    df[\"feedback_text\"]\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# Remove very short feedback (like \"ok\", \"good\")\n",
    "df = df[df[\"clean_text\"].str.len() > 10]\n",
    "\n",
    "print(\"Clean feedback rows:\", len(df))\n",
    "df[[\"feedback_text\", \"clean_text\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cef5b3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 5000\n",
      "After : 25\n"
     ]
    }
   ],
   "source": [
    "# Remove exact duplicate feedback texts\n",
    "df_unique = df.drop_duplicates(subset=[\"clean_text\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"Before:\", len(df))\n",
    "print(\"After :\", len(df_unique))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64991ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (25, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------\n",
    "# LOAD EMBEDDING MODEL\n",
    "# ---------------------------\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# ---------------------------\n",
    "# CREATE EMBEDDINGS\n",
    "# ---------------------------\n",
    "texts = df_unique[\"clean_text\"].tolist()\n",
    "\n",
    "embeddings = model.encode(\n",
    "    texts,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print(\"Embeddings shape:\", embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fabc970b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_unique' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m     pickle.dump(embeddings, f)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Save metadata (to map back to text)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mdf_unique\u001b[49m[[\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfeedback_id\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33morder_id\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mclean_text\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfeedback_category\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msentiment\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     14\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfeedback_date\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     15\u001b[39m ]].to_pickle(\u001b[33m\"\u001b[39m\u001b[33mfeedback_metadata.pkl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Feedback vectors and metadata saved\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df_unique' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save vectors\n",
    "with open(\"C:/Projects/final project/data/feedback_vectors.pkl\", \"wb\") as f:\n",
    "    pickle.dump(embeddings, f)\n",
    "\n",
    "# Save metadata (to map back to text)\n",
    "df_unique[[\n",
    "    \"feedback_id\",\n",
    "    \"order_id\",\n",
    "    \"clean_text\",\n",
    "    \"feedback_category\",\n",
    "    \"sentiment\",\n",
    "    \"feedback_date\"\n",
    "]].to_pickle(\"feedback_metadata.pkl\")\n",
    "\n",
    "print(\"✅ Feedback vectors and metadata saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c182ab2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 384)\n",
      "   feedback_id    order_id                            clean_text  \\\n",
      "0      2234710  1961864118         it was okay, nothing special.   \n",
      "1      5450964  1549769649              the order was incorrect.   \n",
      "2      4823104  9644738826      the product met my expectations.   \n",
      "3      3537464  5427684290  product was damaged during delivery.   \n",
      "4       230696  4898355547                   highly recommended!   \n",
      "\n",
      "  feedback_category sentiment feedback_date  \n",
      "0          Delivery   Neutral    2024-07-17  \n",
      "1    App Experience  Negative    2024-05-28  \n",
      "2    App Experience   Neutral    2023-11-24  \n",
      "3          Delivery  Negative    2023-11-20  \n",
      "4   Product Quality  Positive    2023-04-16  \n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load vectors\n",
    "with open(\"C:/Projects/final project/data/feedback_vectors.pkl\", \"rb\") as f:\n",
    "    embeddings = pickle.load(f)\n",
    "\n",
    "# Load metadata\n",
    "metadata = pd.read_pickle(\"C:/Projects/final project/data/feedback_metadata.pkl\")\n",
    "embeddings = np.array(embeddings)\n",
    "\n",
    "print(embeddings.shape)\n",
    "print(metadata.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71183cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"Why are customers unhappy with fruit orders?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0e3d60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "query_vector = embed_model.encode([user_question])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bf491a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Compare question vector with all feedback vectors\n",
    "similarity_scores = cosine_similarity(query_vector, embeddings)[0]\n",
    "\n",
    "SIMILARITY_THRESHOLD = 0.25  # important\n",
    "\n",
    "top_indices = similarity_scores.argsort()[::-1]\n",
    "\n",
    "relevant_indices = [\n",
    "    i for i in top_indices\n",
    "    if similarity_scores[i] >= SIMILARITY_THRESHOLD\n",
    "][:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c63abb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "delivery was fine, but the product could be better.\n",
      "----\n",
      "delivery was late and i was unhappy.\n",
      "----\n",
      "customer service was not helpful.\n",
      "----\n",
      "the packaging was poor.\n",
      "----\n",
      "items were missing from my order.\n"
     ]
    }
   ],
   "source": [
    "for i, row in retrieved_feedbacks.iterrows():\n",
    "    print(\"----\")\n",
    "    print(row[\"clean_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e9b05bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(relevant_indices) == 0:\n",
    "    answer = \"I don’t have enough customer feedback data to answer this question.\"\n",
    "    print(answer)\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f2afaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_feedbacks = metadata.iloc[relevant_indices]\n",
    "\n",
    "context = \"\\n\".join(\n",
    "    f\"- {text}\"\n",
    "    for text in retrieved_feedbacks[\"clean_text\"].tolist()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa41f7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are a senior business analyst at Blinkit.\n",
    "\n",
    "RULES:\n",
    "- Answer ONLY using the complaints below.\n",
    "- If complaints do not explain the question, say:\n",
    "  \"Insufficient customer feedback to determine root cause.\"\n",
    "\n",
    "Customer complaints:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{user_question}\n",
    "\n",
    "Provide a clear root-cause analysis in business terms.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14614719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided customer complaints, I will attempt to identify the root cause of customer unhappiness with fruit orders.\n",
      "\n",
      "**Root Cause Analysis:**\n",
      "\n",
      "1. **Insufficient Quality Control**: The complaint about the product being \"could be better\" suggests that the quality of the fruits delivered is not meeting customer expectations. This could be due to inadequate quality control measures in place, such as inconsistent sourcing, inadequate storage, or poor handling practices.\n",
      "2. **Inefficient Supply Chain**: The complaint about late delivery suggests that there may be issues with the supply chain, such as inadequate inventory management, inefficient logistics, or poor communication with suppliers. This could lead to delays in receiving fresh fruits, which may not meet customer expectations.\n",
      "3. **Poor Packaging**: The complaint about poor packaging suggests that the fruits may not be being handled and stored properly, leading to damage or spoilage during transit. This could be due to inadequate packaging materials or insufficient training for delivery personnel.\n",
      "4. **Inaccurate Order Fulfillment**: The complaint about items missing from the order suggests that there may be issues with order fulfillment, such as inadequate inventory management or poor communication between the customer and the delivery team.\n",
      "\n",
      "**Root Cause:**\n",
      "\n",
      "Based on the above analysis, the root cause of customer unhappiness with fruit orders appears to be a combination of **Inadequate Quality Control** and **Inefficient Supply Chain**. These two factors are interconnected, as poor quality control can lead to inefficient supply chain operations, and vice versa.\n",
      "\n",
      "**Recommendations:**\n",
      "\n",
      "1. Implement a robust quality control process to ensure that fruits meet customer expectations.\n",
      "2. Optimize the supply chain to reduce delays and improve inventory management.\n",
      "3. Improve packaging materials and training for delivery personnel to prevent damage or spoilage.\n",
      "4. Enhance order fulfillment processes to ensure accurate and complete orders.\n",
      "\n",
      "By addressing these root causes, Blinkit can improve the quality and reliability of its fruit orders, leading to increased customer satisfaction and loyalty.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from groq import Groq\n",
    "import os\n",
    "\n",
    "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
    "response = client.chat.completions.create(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
